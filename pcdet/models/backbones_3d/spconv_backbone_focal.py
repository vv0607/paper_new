from functools import partial # ä»functoolsæ¨¡å—å¯¼å…¥partialï¼Œç”¨äºåˆ›å»ºåå‡½æ•°

import torch # å¯¼å…¥PyTorchåº“
import spconv.pytorch as spconv # å¯¼å…¥spconvåº“ï¼Œç”¨äºç¨€ç–å·ç§¯
import torch.nn as nn # å¯¼å…¥PyTorchçš„ç¥ç»ç½‘ç»œæ¨¡å—

from .focal_sparse_conv.focal_sparse_conv import FocalSparseConv # ä»æœ¬åœ°æ¨¡å—å¯¼å…¥FocalSparseConvç±»
from .SemanticSeg.pyramid_ffn import PyramidFeat2D # ä»æœ¬åœ°æ¨¡å—å¯¼å…¥PyramidFeat2Dç±»


class objDict: # å®šä¹‰ä¸€ä¸ªåä¸ºobjDictçš„ç±»
    @staticmethod # å®šä¹‰ä¸€ä¸ªé™æ€æ–¹æ³•
    def to_object(obj: object, **data): # å®šä¹‰to_objectæ–¹æ³•ï¼Œå°†å­—å…¸æ•°æ®æ›´æ–°åˆ°å¯¹è±¡çš„__dict__ä¸­
        obj.__dict__.update(data) # æ›´æ–°å¯¹è±¡çš„å±æ€§

class ConfigDict: # å®šä¹‰ä¸€ä¸ªåä¸ºConfigDictçš„ç±»
    def __init__(self, name): # å®šä¹‰æ„é€ å‡½æ•°
        self.name = name # åˆå§‹åŒ–nameå±æ€§
    def __getitem__(self, item): # å®šä¹‰__getitem__æ–¹æ³•ï¼Œä½¿å¾—å¯ä»¥åƒå­—å…¸ä¸€æ ·é€šè¿‡é”®è·å–å±æ€§
        return getattr(self, item) # è¿”å›å¯¹è±¡çš„å±æ€§å€¼


class SparseSequentialBatchdict(spconv.SparseSequential): # å®šä¹‰ä¸€ä¸ªç»§æ‰¿è‡ªspconv.SparseSequentialçš„ç±»
    def __init__(self, *args, **kwargs): # å®šä¹‰æ„é€ å‡½æ•°
        super(SparseSequentialBatchdict, self).__init__(*args, **kwargs) # è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°

    def forward(self, input, batch_dict=None): # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•
        for k, module in self._modules.items(): # éå†æ‰€æœ‰å­æ¨¡å—
            if module is None: # å¦‚æœæ¨¡å—ä¸ºç©º
                continue # åˆ™è·³è¿‡
            if isinstance(module, (FocalSparseConv,)): # å¦‚æœæ¨¡å—æ˜¯FocalSparseConvçš„å®ä¾‹
                input, batch_dict = module(input, batch_dict) # æ¨¡å—åŒæ—¶è¿”å›è¾“å‡ºå’Œæ›´æ–°åçš„batch_dict
            else: # å¦åˆ™
                input = module(input) # æ¨¡å—åªè¿”å›è¾“å‡º
        return input, batch_dict # è¿”å›è¾“å‡ºå’Œbatch_dict


def post_act_block(in_channels, out_channels, kernel_size, indice_key=None, stride=1, padding=0, # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»ºåæ¿€æ´»å—
                   conv_type='subm', norm_fn=None): # å‡½æ•°å‚æ•°åŒ…æ‹¬è¾“å…¥/è¾“å‡ºé€šé“ã€å·ç§¯æ ¸å¤§å°ã€indice_keyã€æ­¥é•¿ã€å¡«å……ã€å·ç§¯ç±»å‹å’Œå½’ä¸€åŒ–å‡½æ•°

    if conv_type == 'subm': # å¦‚æœå·ç§¯ç±»å‹æ˜¯'subm'ï¼ˆå­æµå½¢ç¨€ç–å·ç§¯ï¼‰
        conv = spconv.SubMConv3d(in_channels, out_channels, kernel_size, bias=False, indice_key=indice_key) # åˆ›å»ºSubMConv3då®ä¾‹
    elif conv_type == 'spconv': # å¦‚æœå·ç§¯ç±»å‹æ˜¯'spconv'ï¼ˆç¨€ç–å·ç§¯ï¼‰
        conv = spconv.SparseConv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, # åˆ›å»ºSparseConv3då®ä¾‹
                                   bias=False, indice_key=indice_key) # å‚æ•°åŒ…æ‹¬æ­¥é•¿å’Œå¡«å……
    elif conv_type == 'inverseconv': # å¦‚æœå·ç§¯ç±»å‹æ˜¯'inverseconv'ï¼ˆç¨€ç–é€†å·ç§¯ï¼‰
        conv = spconv.SparseInverseConv3d(in_channels, out_channels, kernel_size, indice_key=indice_key, bias=False) # åˆ›å»ºSparseInverseConv3då®ä¾‹
    else: # å¦åˆ™
        raise NotImplementedError # æŠ›å‡ºæœªå®ç°é”™è¯¯

    m = spconv.SparseSequential( # åˆ›å»ºä¸€ä¸ªç¨€ç–åºåˆ—æ¨¡å—
        conv, # åŒ…å«å·ç§¯å±‚
        norm_fn(out_channels), # å½’ä¸€åŒ–å±‚
        nn.ReLU(True), # ReLUæ¿€æ´»å‡½æ•°
    )

    return m # è¿”å›åˆ›å»ºçš„æ¨¡å—


class SparseBasicBlock(spconv.SparseModule): # å®šä¹‰ä¸€ä¸ªç»§æ‰¿è‡ªspconv.SparseModuleçš„ç±»
    expansion = 1 # å®šä¹‰æ‰©å±•å› å­ä¸º1

    def __init__(self, inplanes, planes, stride=1, norm_fn=None, downsample=None, indice_key=None): # å®šä¹‰æ„é€ å‡½æ•°
        super(SparseBasicBlock, self).__init__() # è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°

        assert norm_fn is not None # æ–­è¨€å½’ä¸€åŒ–å‡½æ•°ä¸ä¸ºç©º
        bias = norm_fn is not None # æ ¹æ®å½’ä¸€åŒ–å‡½æ•°æ˜¯å¦å­˜åœ¨æ¥å†³å®šæ˜¯å¦ä½¿ç”¨åç½®
        self.conv1 = spconv.SubMConv3d( # å®šä¹‰ç¬¬ä¸€ä¸ªå­æµå½¢å·ç§¯å±‚
            inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=bias, indice_key=indice_key
        )
        self.bn1 = norm_fn(planes) # å®šä¹‰ç¬¬ä¸€ä¸ªæ‰¹å½’ä¸€åŒ–å±‚
        self.relu = nn.ReLU(True) # å®šä¹‰ReLUæ¿€æ´»å‡½æ•°
        self.conv2 = spconv.SubMConv3d( # å®šä¹‰ç¬¬äºŒä¸ªå­æµå½¢å·ç§¯å±‚
            planes, planes, kernel_size=3, stride=stride, padding=1, bias=bias, indice_key=indice_key
        )
        self.bn2 = norm_fn(planes) # å®šä¹‰ç¬¬äºŒä¸ªæ‰¹å½’ä¸€åŒ–å±‚
        self.downsample = downsample # å®šä¹‰ä¸‹é‡‡æ ·å±‚
        self.stride = stride # ä¿å­˜æ­¥é•¿

    def forward(self, x): # å®šä¹‰å‰å‘ä¼ æ’­æ–¹æ³•
        identity = x # ä¿å­˜è¾“å…¥ä½œä¸ºæ®‹å·®è¿æ¥çš„identity

        out = self.conv1(x) # ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        out = out.replace_feature(self.bn1(out.features)) # ç¬¬ä¸€ä¸ªæ‰¹å½’ä¸€åŒ–
        out = out.replace_feature(self.relu(out.features)) # ReLUæ¿€æ´»

        out = self.conv2(out) # ç¬¬äºŒä¸ªå·ç§¯å±‚
        out = out.replace_feature(self.bn2(out.features)) # ç¬¬äºŒä¸ªæ‰¹å½’ä¸€åŒ–

        if self.downsample is not None: # å¦‚æœå­˜åœ¨ä¸‹é‡‡æ ·å±‚
            identity = self.downsample(x) # å¯¹è¾“å…¥è¿›è¡Œä¸‹é‡‡æ ·

        out = out.replace_feature(out.features + identity.features) # å°†è¾“å‡ºä¸identityç›¸åŠ ï¼ˆæ®‹å·®è¿æ¥ï¼‰
        out = out.replace_feature(self.relu(out.features)) # ReLUæ¿€æ´»

        return out # è¿”å›è¾“å‡º


class VoxelBackBone8xFocal(nn.Module): # å®šä¹‰ä¸€ä¸ªç»§æ‰¿è‡ªnn.Moduleçš„ç±»
    def __init__(self, model_cfg, input_channels, grid_size, **kwargs): # å®šä¹‰æ„é€ å‡½æ•°
        super().__init__() # è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°
        self.model_cfg = model_cfg # ä¿å­˜æ¨¡å‹é…ç½®

        norm_fn = partial(nn.BatchNorm1d, eps=1e-3, momentum=0.01) # åˆ›å»ºä¸€ä¸ªåå‡½æ•°ï¼Œç”¨äºæ‰¹å½’ä¸€åŒ–
        print(f"[DEBUG] Backbone input_channels: {input_channels}")
        self.sparse_shape = grid_size[::-1] + [1, 0, 0] # å®šä¹‰ç¨€ç–å¼ é‡çš„å½¢çŠ¶

        self.conv_input = spconv.SparseSequential( # å®šä¹‰è¾“å…¥å·ç§¯æ¨¡å—
            spconv.SubMConv3d(input_channels, 16, 3, padding=1, bias=False, indice_key='subm1'), # å­æµå½¢å·ç§¯
            norm_fn(16), # æ‰¹å½’ä¸€åŒ–
            nn.ReLU(True), # ReLUæ¿€æ´»
        )

        block = post_act_block # å°†post_act_blockå‡½æ•°èµ‹å€¼ç»™blockå˜é‡

        use_img = model_cfg.get('USE_IMG', False) # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ˜¯å¦ä½¿ç”¨å›¾åƒï¼Œé»˜è®¤ä¸ºFalse
        topk = model_cfg.get('TOPK', True) # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ˜¯å¦ä½¿ç”¨topkï¼Œé»˜è®¤ä¸ºTrue
        threshold = model_cfg.get('THRESHOLD', 0.5) # ä»æ¨¡å‹é…ç½®ä¸­è·å–é˜ˆå€¼ï¼Œé»˜è®¤ä¸º0.5
        kernel_size = model_cfg.get('KERNEL_SIZE', 3) # ä»æ¨¡å‹é…ç½®ä¸­è·å–å·ç§¯æ ¸å¤§å°ï¼Œé»˜è®¤ä¸º3
        mask_multi = model_cfg.get('MASK_MULTI', False) # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ˜¯å¦ä½¿ç”¨å¤šæ©ç ï¼Œé»˜è®¤ä¸ºFalse
        skip_mask_kernel = model_cfg.get('SKIP_MASK_KERNEL', False) # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ˜¯å¦è·³è¿‡æ©ç æ ¸ï¼Œé»˜è®¤ä¸ºFalse
        skip_mask_kernel_image =  model_cfg.get('SKIP_MASK_KERNEL_IMG', False) # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ˜¯å¦è·³è¿‡å›¾åƒæ©ç æ ¸ï¼Œé»˜è®¤ä¸ºFalse
        enlarge_voxel_channels = model_cfg.get('ENLARGE_VOXEL_CHANNELS', -1) # ä»æ¨¡å‹é…ç½®ä¸­è·å–æ‰©å¤§çš„ä½“ç´ é€šé“æ•°ï¼Œé»˜è®¤ä¸º-1
        img_pretrain = model_cfg.get('IMG_PRETRAIN', "checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth") # è·å–å›¾åƒé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        use_stages = model_cfg.get('USE_STAGES', [1, 2, 3]) # è·å–ä½¿ç”¨çš„é˜¶æ®µï¼Œé»˜è®¤ä¸º[1, 2, 3]
        
        if use_img:
            # ğŸ”¥ å…ˆåªç”¨layer1æµ‹è¯•
            model_cfg_seg = dict(
                name='SemDeepLabV3',
                backbone='ResNet50',
                num_class=21,
                args={
                    "feat_extract_layer": ["layer1"],  # â† åªç”¨1å±‚
                    "pretrained_path": img_pretrain
                },
                channel_reduce={
                    "in_channels": [256],
                    "out_channels": [64],  # â† 64é€šé“
                    "kernel_size": [1],
                    "stride": [1],
                    "bias": [False]
                }
            )
            
            cfg_dict = ConfigDict('SemDeepLabV3')
            objDict.to_object(cfg_dict, **model_cfg_seg)
            self.semseg = PyramidFeat2D(optimize=True, model_cfg=cfg_dict)
            
            # åªåˆ›å»ºlayer1çš„èåˆæ¨¡å—
            self.conv_focal_multimodal_layer1 = FocalSparseConv(
                16, 16,
                image_channel=64,  # â† 64é€šé“
                topk=topk,
                threshold=threshold,
                use_img=True,
                skip_mask_kernel=skip_mask_kernel_image,
                voxel_stride=1,
                norm_fn=norm_fn,
                indice_key='spconv_focal_multimodal_layer1'
            )

            # self.conv_focal_multimodal = FocalSparseConv(16, 16, image_channel=model_cfg_seg['channel_reduce']['out_channels'][0], # åˆ›å»ºå¤šæ¨¡æ€ç„¦ç‚¹ç¨€ç–å·ç§¯å®ä¾‹
            #                             topk=topk, threshold=threshold, use_img=True, skip_mask_kernel=skip_mask_kernel_image, # ä¼ å…¥ç›¸å…³å‚æ•°
            #                             voxel_stride=1, norm_fn=norm_fn, indice_key='spconv_focal_multimodal') # ä¼ å…¥ä½“ç´ æ­¥é•¿ã€å½’ä¸€åŒ–å‡½æ•°å’Œindice_key

        special_spconv_fn = partial(FocalSparseConv, mask_multi=mask_multi, enlarge_voxel_channels=enlarge_voxel_channels, # åˆ›å»ºä¸€ä¸ªç”¨äºFocalSparseConvçš„åå‡½æ•°
                                    topk=topk, threshold=threshold, kernel_size=kernel_size, padding=kernel_size//2, # ä¼ å…¥ç›¸å…³å‚æ•°
                                    skip_mask_kernel=skip_mask_kernel) # ä¼ å…¥æ˜¯å¦è·³è¿‡æ©ç æ ¸
        self.use_img = use_img # ä¿å­˜æ˜¯å¦ä½¿ç”¨å›¾åƒçš„æ ‡å¿—

        self.conv1 = SparseSequentialBatchdict( # å®šä¹‰ç¬¬ä¸€ä¸ªå·ç§¯å—
            block(16, 16, 3, norm_fn=norm_fn, padding=1, indice_key='subm1'), # ä¸€ä¸ªåŸºæœ¬çš„åæ¿€æ´»å—
            special_spconv_fn(16, 16, voxel_stride=1, norm_fn=norm_fn, indice_key='focal1') if 1 in use_stages else None, # å¦‚æœä½¿ç”¨é˜¶æ®µ1ï¼Œåˆ™æ·»åŠ ä¸€ä¸ªç„¦ç‚¹ç¨€ç–å·ç§¯
        )

        self.conv2 =SparseSequentialBatchdict( # å®šä¹‰ç¬¬äºŒä¸ªå·ç§¯å—
            # [1600, 1408, 41] <- [800, 704, 21] # æ³¨é‡Šï¼šè¾“å…¥è¾“å‡ºçš„ç¨€ç–å¼ é‡å½¢çŠ¶å˜åŒ–
            block(16, 32, 3, norm_fn=norm_fn, stride=2, padding=1, indice_key='spconv2', conv_type='spconv'), # ä¸€ä¸ªå¸¦æ­¥é•¿çš„å·ç§¯å—ï¼Œç”¨äºä¸‹é‡‡æ ·
            block(32, 32, 3, norm_fn=norm_fn, padding=1, indice_key='subm2'), # ä¸¤ä¸ªåŸºæœ¬çš„åæ¿€æ´»å—
            block(32, 32, 3, norm_fn=norm_fn, padding=1, indice_key='subm2'),
            special_spconv_fn(32, 32, voxel_stride=2, norm_fn=norm_fn, indice_key='focal2') if 2 in use_stages else None, # å¦‚æœä½¿ç”¨é˜¶æ®µ2ï¼Œåˆ™æ·»åŠ ä¸€ä¸ªç„¦ç‚¹ç¨€ç–å·ç§¯
        )

        self.conv3 = SparseSequentialBatchdict( # å®šä¹‰ç¬¬ä¸‰ä¸ªå·ç§¯å—
            # [800, 704, 21] <- [400, 352, 11] # æ³¨é‡Šï¼šè¾“å…¥è¾“å‡ºçš„ç¨€ç–å¼ é‡å½¢çŠ¶å˜åŒ–
            block(32, 64, 3, norm_fn=norm_fn, stride=2, padding=1, indice_key='spconv3', conv_type='spconv'), # ä¸€ä¸ªå¸¦æ­¥é•¿çš„å·ç§¯å—ï¼Œç”¨äºä¸‹é‡‡æ ·
            block(64, 64, 3, norm_fn=norm_fn, padding=1, indice_key='subm3'), # ä¸¤ä¸ªåŸºæœ¬çš„åæ¿€æ´»å—
            block(64, 64, 3, norm_fn=norm_fn, padding=1, indice_key='subm3'),
            special_spconv_fn(64, 64, voxel_stride=4, norm_fn=norm_fn, indice_key='focal3') if 3 in use_stages else None, # å¦‚æœä½¿ç”¨é˜¶æ®µ3ï¼Œåˆ™æ·»åŠ ä¸€ä¸ªç„¦ç‚¹ç¨€ç–å·ç§¯
        )

        self.conv4 = SparseSequentialBatchdict( # å®šä¹‰ç¬¬å››ä¸ªå·ç§¯å—
            # [400, 352, 11] <- [200, 176, 5] # æ³¨é‡Šï¼šè¾“å…¥è¾“å‡ºçš„ç¨€ç–å¼ é‡å½¢çŠ¶å˜åŒ–
            block(64, 64, 3, norm_fn=norm_fn, stride=2, padding=(0, 1, 1), indice_key='spconv4', conv_type='spconv'), # ä¸€ä¸ªå¸¦æ­¥é•¿çš„å·ç§¯å—ï¼Œç”¨äºä¸‹é‡‡æ ·
            block(64, 64, 3, norm_fn=norm_fn, padding=1, indice_key='subm4'), # ä¸¤ä¸ªåŸºæœ¬çš„åæ¿€æ´»å—
            block(64, 64, 3, norm_fn=norm_fn, padding=1, indice_key='subm4'),
        )

        last_pad = 0 # åˆå§‹åŒ–æœ€åçš„å¡«å……ä¸º0
        last_pad = self.model_cfg.get('last_pad', last_pad) # ä»æ¨¡å‹é…ç½®ä¸­è·å–æœ€åçš„å¡«å……
        self.conv_out = spconv.SparseSequential( # å®šä¹‰è¾“å‡ºå·ç§¯æ¨¡å—
            # [200, 150, 5] -> [200, 150, 2] # æ³¨é‡Šï¼šè¾“å…¥è¾“å‡ºçš„ç¨€ç–å¼ é‡å½¢çŠ¶å˜åŒ–
            spconv.SparseConv3d(64, 128, (3, 1, 1), stride=(2, 1, 1), padding=last_pad, # ä¸€ä¸ªç¨€ç–å·ç§¯å±‚ï¼Œç”¨äºæœ€ç»ˆçš„ä¸‹é‡‡æ ·
                                bias=False, indice_key='spconv_down2'),
            norm_fn(128), # æ‰¹å½’ä¸€åŒ–
            nn.ReLU(True), # ReLUæ¿€æ´»
        )
        self.num_point_features = 128 # å®šä¹‰ç‚¹ç‰¹å¾çš„æ•°é‡
        self.backbone_channels = { # å®šä¹‰ä¸»å¹²ç½‘ç»œå„å±‚çš„è¾“å‡ºé€šé“æ•°
            'x_conv1': 16,
            'x_conv2': 32,
            'x_conv3': 64,
            'x_conv4': 64
        }
    def forward(self, batch_dict):
        """
        ç°åœ¨ batch_dict['voxel_features'] å·²ç»æ˜¯æ‹¼æ¥åçš„ (N+M, 7)
        batch_dict['voxel_coords'] å·²ç»æ˜¯æ‹¼æ¥åçš„ (N+M, 4)
        """
        voxel_features = batch_dict['voxel_features']  # (N+M, 7)
        voxel_coords = batch_dict['voxel_coords']      # (N+M, 4)
        batch_size = batch_dict['batch_size']
        
        print(f"[DEBUG Backbone] voxel_features shape: {voxel_features.shape}")
        print(f"[DEBUG Backbone] voxel_coords shape: {voxel_coords.shape}")
        
        # ç¡®ä¿åæ ‡æ˜¯æ•´æ•°ç±»å‹
        if not isinstance(voxel_coords, torch.Tensor):
            voxel_coords = torch.from_numpy(voxel_coords)
        voxel_coords = voxel_coords.int().contiguous()
        
        # éªŒè¯
        assert voxel_coords.ndim == 2, f"coords must be 2D, got {voxel_coords.shape}"
        assert voxel_coords.shape[1] == 4, f"coords must be (N, 4), got {voxel_coords.shape}"
        assert voxel_features.shape[1] == 7, f"features must be (N, 7), got {voxel_features.shape}"
        
        # åˆ›å»ºç¨€ç–å¼ é‡
        input_sp_tensor = spconv.SparseConvTensor(
            features=voxel_features,
            indices=voxel_coords,
            spatial_shape=self.sparse_shape,
            batch_size=batch_size
        )
        
        batch_dict['loss_box_of_pts'] = 0

        x = self.conv_input(input_sp_tensor)
        x_conv1, batch_dict = self.conv1(x, batch_dict)

        # if self.use_img:
        #     x_image = self.semseg(batch_dict['images'])['layer1_feat2d']
        #     x_conv1, batch_dict = self.conv_focal_multimodal(x_conv1, batch_dict, x_image)

        # x_conv2, batch_dict = self.conv2(x_conv1, batch_dict)
        # x_conv3, batch_dict = self.conv3(x_conv2, batch_dict)
        # ğŸ”¥ æå–å¤šå°ºåº¦å›¾åƒç‰¹å¾
        if self.use_img:
            if 'calib' not in batch_dict or 'images' not in batch_dict:
                print(f"[WARNING] Missing calib or images")
            else:
                image_features = self.semseg(batch_dict['images'])
                x_image = image_features['layer1_feat2d']
                
                # æ·»åŠ è°ƒè¯•è¾“å‡º
                print(f"[DEBUG] x_image shape: {x_image.shape}")
                print(f"[DEBUG] x_conv1 features shape: {x_conv1.features.shape}")
                
                x_conv1, batch_dict = self.conv_focal_multimodal_layer1(
                    x_conv1, batch_dict, x_image
                )

        x_conv2, batch_dict = self.conv2(x_conv1, batch_dict)
        x_conv3, batch_dict = self.conv3(x_conv2, batch_dict)

        x_conv4, batch_dict = self.conv4(x_conv3, batch_dict)

        out = self.conv_out(x_conv4)

        batch_dict.update({
            'encoded_spconv_tensor': out,
            'encoded_spconv_tensor_stride': 8
        })
        batch_dict.update({
            'multi_scale_3d_features': {
                'x_conv1': x_conv1,
                'x_conv2': x_conv2,
                'x_conv3': x_conv3,
                'x_conv4': x_conv4,
            }
        })
        batch_dict.update({
            'multi_scale_3d_strides': {
                'x_conv1': 1,
                'x_conv2': 2,
                'x_conv3': 4,
                'x_conv4': 8,
            }
        })
        
        # è½¬æ¢ä¸º BEV ç‰¹å¾
        spatial_features = out.dense()
        N, C, D, H, W = spatial_features.shape
        
        if D > 1:
            spatial_features = spatial_features.mean(dim=2)
        else:
            spatial_features = spatial_features.squeeze(2)
        
        batch_dict['spatial_features'] = spatial_features

        return batch_dict
